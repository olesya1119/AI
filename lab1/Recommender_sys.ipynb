{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HY6tZVZEFUu"
   },
   "source": [
    "# Лабораторная работа: Рекомендательные системы\n",
    "\n",
    "## Теоретическая часть\n",
    "\n",
    "### 1. Суть задачи рекомендательных систем\n",
    "Рекомендательные системы – это алгоритмы, которые анализируют поведение пользователей и предлагают персонализированные рекомендации товаров, фильмов, музыки и других объектов. Основная цель – предсказать предпочтения пользователей на основе имеющихся данных о взаимодействиях.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0NOMEMPELnN"
   },
   "source": [
    "### 2. Метод коллаборативной фильтрации\n",
    "Коллаборативная фильтрация (Collaborative Filtering, CF) – это метод рекомендаций, основанный на анализе поведения пользователей. Он работает на основе предположения, что пользователи с похожими предпочтениями в прошлом будут делать схожий выбор в будущем.\n",
    "\n",
    "Существует два основных подхода:\n",
    "1. **User-based CF** – рекомендации строятся на основе сходства пользователей.\n",
    "2. **Item-based CF** – рекомендации строятся на основе сходства объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHKX45JNEPn4"
   },
   "source": [
    "### 3. Латентные факторные модели (Matrix Factorization)\n",
    "Коллаборативная фильтрация может быть реализована через матричное разложение. Пусть у нас есть матрица взаимодействий пользователей и объектов R, где $( R_{u,i} )$ – оценка пользователя ( u ) для объекта ( i ). Тогда разложение можно представить в виде:\n",
    "$$\n",
    "R \\approx U \\cdot V^T\n",
    "$$\n",
    "где:\n",
    "- ( U ) – матрица эмбеддингов пользователей,\n",
    "- ( V ) – матрица эмбеддингов объектов.\n",
    "\n",
    "Предсказание рейтинга рассчитывается как:\n",
    "$$\n",
    "\\hat{R}_{u,i} = U_u \\cdot V_i^T\n",
    "$$\n",
    "\n",
    "В данной лабораторной работе предполагается использование **нейросетевого метода**, который обучает эмбеддинги пользователей и объектов с помощью полносвязных слоев. Входные данные – индексы пользователей и объектов, которые преобразуются в векторные представления, а затем подаются на вход нейросети.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_pHnJogEspk"
   },
   "source": [
    "## Практическая часть\n",
    "В данной работе вам предлагается реализовать рекомендательную систему на основе метода коллаборативной фильтрации, используя нейросетевую модель. Вы должны:\n",
    "1. Подготовить данные: загрузить свой датасет (например, рейтинг фильмов, товаров, книг и т. д.).\n",
    "2. Разбить данные на тренировочный и тестовый наборы.\n",
    "3. Обучить модель, используя эмбеддинги пользователей и объектов.\n",
    "4. Оценить качество модели на тестовом наборе.\n",
    "5. Вывести список рекомендаций для выбранного пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4RGbYAJcHFf6"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Проекты\\Нейронки\\AI\\AI\\venv\\Lib\\site-packages\\pandas\\__init__.py:58\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     60\u001b[39m     ArrowDtype,\n\u001b[32m     61\u001b[39m     Int8Dtype,\n\u001b[32m     62\u001b[39m     Int16Dtype,\n\u001b[32m     63\u001b[39m     Int32Dtype,\n\u001b[32m     64\u001b[39m     Int64Dtype,\n\u001b[32m     65\u001b[39m     UInt8Dtype,\n\u001b[32m     66\u001b[39m     UInt16Dtype,\n\u001b[32m     67\u001b[39m     UInt32Dtype,\n\u001b[32m     68\u001b[39m     UInt64Dtype,\n\u001b[32m     69\u001b[39m     Float32Dtype,\n\u001b[32m     70\u001b[39m     Float64Dtype,\n\u001b[32m     71\u001b[39m     CategoricalDtype,\n\u001b[32m     72\u001b[39m     PeriodDtype,\n\u001b[32m     73\u001b[39m     IntervalDtype,\n\u001b[32m     74\u001b[39m     DatetimeTZDtype,\n\u001b[32m     75\u001b[39m     StringDtype,\n\u001b[32m     76\u001b[39m     BooleanDtype,\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     78\u001b[39m     NA,\n\u001b[32m     79\u001b[39m     isna,\n\u001b[32m     80\u001b[39m     isnull,\n\u001b[32m     81\u001b[39m     notna,\n\u001b[32m     82\u001b[39m     notnull,\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     84\u001b[39m     Index,\n\u001b[32m     85\u001b[39m     CategoricalIndex,\n\u001b[32m     86\u001b[39m     RangeIndex,\n\u001b[32m     87\u001b[39m     MultiIndex,\n\u001b[32m     88\u001b[39m     IntervalIndex,\n\u001b[32m     89\u001b[39m     TimedeltaIndex,\n\u001b[32m     90\u001b[39m     DatetimeIndex,\n\u001b[32m     91\u001b[39m     PeriodIndex,\n\u001b[32m     92\u001b[39m     IndexSlice,\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     94\u001b[39m     NaT,\n\u001b[32m     95\u001b[39m     Period,\n\u001b[32m     96\u001b[39m     period_range,\n\u001b[32m     97\u001b[39m     Timedelta,\n\u001b[32m     98\u001b[39m     timedelta_range,\n\u001b[32m     99\u001b[39m     Timestamp,\n\u001b[32m    100\u001b[39m     date_range,\n\u001b[32m    101\u001b[39m     bdate_range,\n\u001b[32m    102\u001b[39m     Interval,\n\u001b[32m    103\u001b[39m     interval_range,\n\u001b[32m    104\u001b[39m     DateOffset,\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    106\u001b[39m     to_numeric,\n\u001b[32m    107\u001b[39m     to_datetime,\n\u001b[32m    108\u001b[39m     to_timedelta,\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    110\u001b[39m     Flags,\n\u001b[32m    111\u001b[39m     Grouper,\n\u001b[32m    112\u001b[39m     factorize,\n\u001b[32m    113\u001b[39m     unique,\n\u001b[32m    114\u001b[39m     NamedAgg,\n\u001b[32m    115\u001b[39m     array,\n\u001b[32m    116\u001b[39m     Categorical,\n\u001b[32m    117\u001b[39m     set_eng_float_format,\n\u001b[32m    118\u001b[39m     Series,\n\u001b[32m    119\u001b[39m     DataFrame,\n\u001b[32m    120\u001b[39m )\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m col\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Проекты\\Нейронки\\AI\\AI\\venv\\Lib\\site-packages\\pandas\\core\\api.py:46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array  \u001b[38;5;66;03m# noqa: ICN001\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Flags\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     47\u001b[39m     Grouper,\n\u001b[32m     48\u001b[39m     NamedAgg,\n\u001b[32m     49\u001b[39m )\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     51\u001b[39m     CategoricalIndex,\n\u001b[32m     52\u001b[39m     DatetimeIndex,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     TimedeltaIndex,\n\u001b[32m     59\u001b[39m )\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     61\u001b[39m     bdate_range,\n\u001b[32m     62\u001b[39m     date_range,\n\u001b[32m     63\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Проекты\\Нейронки\\AI\\AI\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     DataFrameGroupBy,\n\u001b[32m      3\u001b[39m     NamedAgg,\n\u001b[32m      4\u001b[39m     SeriesGroupBy,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GroupBy\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrouper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Grouper\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Проекты\\Нейронки\\AI\\AI\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:57\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     52\u001b[39m     isna,\n\u001b[32m     53\u001b[39m     notna,\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m algorithms\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     58\u001b[39m     GroupByApply,\n\u001b[32m     59\u001b[39m     maybe_mangle_lambdas,\n\u001b[32m     60\u001b[39m     reconstruct_func,\n\u001b[32m     61\u001b[39m     validate_func_kwargs,\n\u001b[32m     62\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcom\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Проекты\\Нейронки\\AI\\AI\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:19\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     TYPE_CHECKING,\n\u001b[32m     11\u001b[39m     Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     cast,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minternals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BlockValuesRefs\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     AggFuncType,\n\u001b[32m     22\u001b[39m     AggFuncTypeBase,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     npt,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_optional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m import_optional_dependency\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:648\u001b[39m, in \u001b[36mModuleSpec.parent\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;129m@cached\u001b[39m.setter\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached\u001b[39m(\u001b[38;5;28mself\u001b[39m, cached):\n\u001b[32m    646\u001b[39m     \u001b[38;5;28mself\u001b[39m._cached = cached\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparent\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    650\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The name of the module's parent.\"\"\"\u001b[39;00m\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.submodule_search_locations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Импорты\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Определяем устройство (используем GPU, если доступно)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1739028831727,
     "user": {
      "displayName": "Vadim Burdukov",
      "userId": "10285805951518216584"
     },
     "user_tz": -420
    },
    "id": "R8U1eQv0HIll",
    "outputId": "07f89063-b93a-4a52-c730-c3ead04211e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-08 15:33:50--  http://files.grouplens.org/datasets/movielens/ml-100k/u.data\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1979173 (1.9M)\n",
      "Saving to: ‘ratings.csv’\n",
      "\n",
      "ratings.csv         100%[===================>]   1.89M  4.23MB/s    in 0.4s    \n",
      "\n",
      "2025-02-08 15:33:51 (4.23 MB/s) - ‘ratings.csv’ saved [1979173/1979173]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k/u.data -O ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AP-5uXk_HQ7K"
   },
   "outputs": [],
   "source": [
    "# Определяем названия столбцов\n",
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ratings.csv', sep='\\t', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-_der2-HTid"
   },
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "\n",
    "# Удаляем ненужный столбец timestamp\n",
    "df = df.drop(columns=['timestamp'])\n",
    "\n",
    "# Преобразуем идентификаторы пользователей и фильмов (начинаем с 0 для удобства в PyTorch)\n",
    "df['user_id'] -= 1\n",
    "df['item_id'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAFL8GvcHetb"
   },
   "outputs": [],
   "source": [
    "# Определяем датасет PyTorch\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJwM8zthHgnq"
   },
   "outputs": [],
   "source": [
    "# Определяем нейросетевую модель для коллаборативной фильтрации\n",
    "class RecommenderNN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
    "        super(RecommenderNN, self).__init__()\n",
    "        # Эмбеддинги пользователей и фильмов\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Полносвязные слои для предсказания рейтинга\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Получаем эмбеддинги пользователя и фильма\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "\n",
    "        # Объединяем эмбеддинги\n",
    "        x = torch.cat([user_emb, item_emb], dim=1)\n",
    "\n",
    "        # Пропускаем через полносвязные слои\n",
    "        return self.fc_layers(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUjmqHfGHi9z"
   },
   "outputs": [],
   "source": [
    "# Определяем количество пользователей и фильмов\n",
    "num_users = df['user_id'].nunique()\n",
    "num_items = df['item_id'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsD675h6HtHB"
   },
   "outputs": [],
   "source": [
    "# Создаём датасеты и загрузчики данных\n",
    "dataset = RatingsDataset(df)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2l11Y4PHvd_"
   },
   "outputs": [],
   "source": [
    "# Инициализация модели\n",
    "model = RecommenderNN(num_users, num_items).to(device)\n",
    "\n",
    "# Определяем функцию потерь (MSE) и оптимизатор (Adam)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38696,
     "status": "ok",
     "timestamp": 1739028906040,
     "user": {
      "displayName": "Vadim Burdukov",
      "userId": "10285805951518216584"
     },
     "user_tz": -420
    },
    "id": "pCVLsYxMIYgS",
    "outputId": "a0ac4835-f7af-46c7-aa34-799ab7e7a2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9276248147964478\n",
      "Epoch 2, Loss: 0.8800954188585282\n",
      "Epoch 3, Loss: 0.8486059767961502\n",
      "Epoch 4, Loss: 0.8204712383508682\n",
      "Epoch 5, Loss: 0.7907023668289185\n",
      "Epoch 6, Loss: 0.7545609577417374\n",
      "Epoch 7, Loss: 0.7237094497442246\n",
      "Epoch 8, Loss: 0.6898156618118286\n",
      "Epoch 9, Loss: 0.6569084687709809\n",
      "Epoch 10, Loss: 0.6269937048673629\n",
      "\n",
      "Test RMSE: 0.9887, Test MAE: 0.7760\n",
      "\n",
      "Recommendations for random users:\n",
      "User 698: Recommended items [1536 1643  835 1456 1645]\n",
      "User 34: Recommended items [1536  285 1643  814 1642]\n",
      "User 640: Recommended items [1643 1467 1536 1367 1599]\n",
      "User 172: Recommended items [1643 1467  923 1536  189]\n",
      "User 219: Recommended items [1643 1536 1656  814   98]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_ratings = []\n",
    "    for users, items, ratings in train_loader:\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().detach().numpy())\n",
    "        all_ratings.extend(ratings.cpu().detach().numpy())\n",
    "\n",
    "    # Средняя ошибка предсказания на тренировочной выборке\n",
    "    rmse = math.sqrt(mean_squared_error(all_ratings, all_predictions))\n",
    "    mae = mean_absolute_error(all_ratings, all_predictions)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "# Оценка модели на тестовом наборе\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_ratings = []\n",
    "with torch.no_grad():\n",
    "    for users, items, ratings in test_loader:\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        predictions = model(users, items)\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "        test_ratings.extend(ratings.cpu().numpy())\n",
    "\n",
    "# Средняя ошибка на тестовом наборе\n",
    "test_rmse = math.sqrt(mean_squared_error(test_ratings, test_predictions))\n",
    "test_mae = mean_absolute_error(test_ratings, test_predictions)\n",
    "\n",
    "print(f'\\nTest RMSE: {test_rmse:.4f}, Test MAE: {test_mae:.4f}')\n",
    "\n",
    "# Рекомендации для нескольких случайных пользователей\n",
    "random_users = np.random.choice(df['user_id'].unique(), size=5)\n",
    "\n",
    "print(\"\\nRecommendations for random users:\")\n",
    "for user_id in random_users:\n",
    "    # Предсказания для всех объектов для выбранного пользователя\n",
    "    user_tensor = torch.tensor([user_id] * num_items, dtype=torch.long).to(device)\n",
    "    item_tensor = torch.tensor(range(num_items), dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_tensor, item_tensor).cpu().numpy()\n",
    "\n",
    "    # Выбираем топ-5 рекомендованных объектов\n",
    "    top_items = predictions.argsort()[-5:][::-1]\n",
    "\n",
    "    print(f\"User {user_id + 1}: Recommended items {top_items + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgL-CfwSIawc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
