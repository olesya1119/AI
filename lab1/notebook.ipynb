{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842afd64",
   "metadata": {},
   "source": [
    "# Лабораторная работа: Рекомендательные системы\n",
    "\n",
    "## Теоретическая часть\n",
    "\n",
    "### 1. Суть задачи рекомендательных систем\n",
    "Рекомендательные системы – это алгоритмы, которые анализируют поведение пользователей и предлагают персонализированные рекомендации товаров, фильмов, музыки и других объектов. Основная цель – предсказать предпочтения пользователей на основе имеющихся данных о взаимодействиях.\n",
    "\n",
    "### 2. Метод коллаборативной фильтрации\n",
    "Коллаборативная фильтрация (Collaborative Filtering, CF) – это метод рекомендаций, основанный на анализе поведения пользователей. Он работает на основе предположения, что пользователи с похожими предпочтениями в прошлом будут делать схожий выбор в будущем.\n",
    "\n",
    "Существует два основных подхода:\n",
    "1. **User-based CF** – рекомендации строятся на основе сходства пользователей.\n",
    "2. **Item-based CF** – рекомендации строятся на основе сходства объектов.\n",
    "\n",
    "### 3. Латентные факторные модели (Matrix Factorization)\n",
    "Коллаборативная фильтрация может быть реализована через матричное разложение. Пусть у нас есть матрица взаимодействий пользователей и объектов R, где $( R_{u,i} )$ – оценка пользователя ( u ) для объекта ( i ). Тогда разложение можно представить в виде:\n",
    "$$\n",
    "R \\approx U \\cdot V^T\n",
    "$$\n",
    "где:\n",
    "- ( U ) – матрица эмбеддингов пользователей,\n",
    "- ( V ) – матрица эмбеддингов объектов.\n",
    "\n",
    "Предсказание рейтинга рассчитывается как:\n",
    "$$\n",
    "\\hat{R}_{u,i} = U_u \\cdot V_i^T\n",
    "$$\n",
    "\n",
    "В данной лабораторной работе предполагается использование **нейросетевого метода**, который обучает эмбеддинги пользователей и объектов с помощью полносвязных слоев. Входные данные – индексы пользователей и объектов, которые преобразуются в векторные представления, а затем подаются на вход нейросети.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a7cfb0",
   "metadata": {},
   "source": [
    "## Практическая часть\n",
    "В данной работе вам предлагается реализовать рекомендательную систему на основе метода коллаборативной фильтрации, используя нейросетевую модель. Вы должны:\n",
    "1. Подготовить данные: загрузить свой датасет (например, рейтинг фильмов, товаров, книг и т. д.).\n",
    "2. Разбить данные на тренировочный и тестовый наборы.\n",
    "3. Обучить модель, используя эмбеддинги пользователей и объектов.\n",
    "4. Оценить качество модели на тестовом наборе.\n",
    "5. Вывести список рекомендаций для выбранного пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6709a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Импорты\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Определяем устройство (используем GPU, если доступно)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d08ac1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До обрезки:\n",
      "  пользователей: 82,519\n",
      "  аниме:         11,439\n",
      "  взаимодействий: 9,015,302\n",
      "   user_id  anime_id  rating  user_idx  anime_idx\n",
      "0        1       454       3         0          0\n",
      "1        1     28761       8         0          1\n",
      "2        1      6682       5         0          2\n",
      "3        1      9624       6         0          3\n",
      "4        1     38101       7         0          4\n",
      "После обрезки:\n",
      "  пользователей: 3,000\n",
      "  аниме:         10,736\n",
      "  взаимодействий: 1,887,252\n"
     ]
    }
   ],
   "source": [
    "anime_df = pd.read_csv('animes.csv')\n",
    "# Загружаем rating.csv \n",
    "ratings_df = pd.read_csv('ratings.csv')\n",
    "ratings_df = ratings_df.drop_duplicates()\n",
    "\n",
    "# Фильтруем только положительные рейтинги ( > 0, поскольку 0 - без рейтинга)\n",
    "ratings_df = ratings_df[ratings_df['rating'] > 0]\n",
    "\n",
    "# Преобразуем идентификаторы пользователей и аниме (начинаем с 0 для удобства в PyTorch)\n",
    "user_id_map = {old: new for new, old in enumerate(ratings_df['user_id'].unique())}\n",
    "anime_id_map = {old: new for new, old in enumerate(ratings_df['anime_id'].unique())}\n",
    "\n",
    "ratings_df['user_idx'] = ratings_df['user_id'].map(user_id_map)\n",
    "ratings_df['anime_idx'] = ratings_df['anime_id'].map(anime_id_map)\n",
    "\n",
    "print(f\"До обрезки:\")\n",
    "print(f\"  пользователей: {ratings_df['user_idx'].nunique():,}\")\n",
    "print(f\"  аниме:         {ratings_df['anime_idx'].nunique():,}\")\n",
    "print(f\"  взаимодействий: {len(ratings_df):,}\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "user_activity = ratings_df['user_id'].value_counts()\n",
    "N = 3000\n",
    "top_users = user_activity.head(N).index\n",
    "\n",
    "# Оставляем только их\n",
    "ratings_df = ratings_df[ratings_df['user_id'].isin(top_users)].copy()\n",
    "\n",
    "# Обязательно перестраиваем индексы после фильтрации!\n",
    "ratings_df = ratings_df.reset_index(drop=True)\n",
    "\n",
    "user_id_map = {old: new for new, old in enumerate(ratings_df['user_id'].unique())}\n",
    "anime_id_map = {old: new for new, old in enumerate(ratings_df['anime_id'].unique())}\n",
    "\n",
    "ratings_df['user_idx']  = ratings_df['user_id'].map(user_id_map)\n",
    "ratings_df['anime_idx'] = ratings_df['anime_id'].map(anime_id_map)\n",
    "\n",
    "print(\"После обрезки:\")\n",
    "print(f\"  пользователей: {ratings_df['user_idx'].nunique():,}\")\n",
    "print(f\"  аниме:         {ratings_df['anime_idx'].nunique():,}\")\n",
    "print(f\"  взаимодействий: {len(ratings_df):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем датасет PyTorch\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df['user_idx'].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(df['anime_idx'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15928c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем нейросетевую модель для коллаборативной фильтрации\n",
    "class RecommenderNN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
    "        super(RecommenderNN, self).__init__()\n",
    "        # Эмбеддинги пользователей и аниме\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Полносвязные слои для предсказания рейтинга\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Получаем эмбеддинги пользователя и аниме\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "\n",
    "        # Объединяем эмбеддинги\n",
    "        x = torch.cat([user_emb, item_emb], dim=1)\n",
    "\n",
    "        # Пропускаем через полносвязные слои\n",
    "        return self.fc_layers(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем количество пользователей и аниме\n",
    "num_users = len(user_id_map)\n",
    "num_items = len(anime_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём датасеты и загрузчики данных\n",
    "dataset = RatingsDataset(ratings_df)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация модели\n",
    "model = RecommenderNN(num_users, num_items).to(device)\n",
    "\n",
    "# Определяем функцию потерь (MSE) и оптимизатор (Adam)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "431517ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.536280402317179, Train RMSE: 1.2395, Train MAE: 0.9379\n",
      "Epoch 2, Loss: 1.3315215431970808, Train RMSE: 1.1539, Train MAE: 0.8708\n",
      "Epoch 3, Loss: 1.2784823856533754, Train RMSE: 1.1307, Train MAE: 0.8514\n",
      "Epoch 4, Loss: 1.2406577561654666, Train RMSE: 1.1138, Train MAE: 0.8379\n",
      "Epoch 5, Loss: 1.2136707895347634, Train RMSE: 1.1017, Train MAE: 0.8278\n",
      "Epoch 6, Loss: 1.18782865750871, Train RMSE: 1.0899, Train MAE: 0.8184\n",
      "Epoch 7, Loss: 1.1636571633796058, Train RMSE: 1.0787, Train MAE: 0.8098\n",
      "Epoch 8, Loss: 1.1381805875331075, Train RMSE: 1.0669, Train MAE: 0.8001\n",
      "Epoch 9, Loss: 1.1140658042193985, Train RMSE: 1.0555, Train MAE: 0.7915\n",
      "Epoch 10, Loss: 1.090787140385272, Train RMSE: 1.0444, Train MAE: 0.7831\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Обучение модели\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_ratings = []\n",
    "    for users, items, ratings in train_loader:\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().detach().numpy())\n",
    "        all_ratings.extend(ratings.cpu().detach().numpy())\n",
    "\n",
    "    # Средняя ошибка предсказания на тренировочной выборке\n",
    "    rmse = math.sqrt(mean_squared_error(all_ratings, all_predictions))\n",
    "    mae = mean_absolute_error(all_ratings, all_predictions)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}, Train RMSE: {rmse:.4f}, Train MAE: {mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ac435",
   "metadata": {},
   "source": [
    "На каждой следующей эпохе метрики улучшаются, нет переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63592452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 1.1293, Test MAE: 0.8505\n"
     ]
    }
   ],
   "source": [
    "# Оценка модели на тестовом наборе\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_ratings = []\n",
    "with torch.no_grad():\n",
    "    for users, items, ratings in test_loader:\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        predictions = model(users, items)\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "        test_ratings.extend(ratings.cpu().numpy())\n",
    "\n",
    "# Средняя ошибка на тестовом наборе\n",
    "test_rmse = math.sqrt(mean_squared_error(test_ratings, test_predictions))\n",
    "test_mae = mean_absolute_error(test_ratings, test_predictions)\n",
    "\n",
    "print(f'\\nTest RMSE: {test_rmse:.4f}, Test MAE: {test_mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ce067",
   "metadata": {},
   "source": [
    "- RMSE: 1.1293 — модель в среднем ошибается на ~1.13 балла в предсказании рейтинга. Это приемлемый результат, указывающий на то, что предсказания близки к реальным\n",
    "- MAE: 0.8505 — средняя абсолютная ошибка ~0.85 балла, что подтверждает стабильность модели. MAE ниже RMSE говорит о том, что крупных выбросов ошибок мало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0201a0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Персонализированные рекомендации (топ-5 аниме) для случайных пользователей:\n",
      "Пользователь 81028: Рекомендуемые аниме: ['Monster', 'Ginga Eiyuu Densetsu', 'Fullmetal Alchemist: Brotherhood', 'Gintama・ゑｽｰ', 'Violet Evergarden Movie']\n",
      "Пользователь 100770: Рекомендуемые аниме: ['Clannad: After Story', \"Gintama': Enchousen\", 'Digimon Adventure: Last Evolution Kizuna', 'Kimetsu no Yaiba Movie: Mugen Ressha-hen']\n",
      "Пользователь 36894: Рекомендуемые аниме: ['Great Teacher Onizuka', 'Ginga Eiyuu Densetsu', 'Code Geass: Hangyaku no Lelouch R2', 'Evangelion: 2.0 You Can (Not) Advance', 'Fullmetal Alchemist: Brotherhood']\n",
      "Пользователь 3394: Рекомендуемые аниме: ['Hellsing Ultimate', 'Clannad: After Story', 'Fullmetal Alchemist: Brotherhood', 'Angel Beats!', 'Kimetsu no Yaiba Movie: Mugen Ressha-hen']\n",
      "Пользователь 29984: Рекомендуемые аниме: ['Bishoujo Senshi Sailor Moon S', 'Yokohama Kaidashi Kikou: Quiet Country Cafe', 'Ashita no Joe', 'Gosenzo-sama Banbanzai!', 'Hyouge Mono']\n"
     ]
    }
   ],
   "source": [
    "idx_to_anime = {v: k for k, v in anime_id_map.items()}\n",
    "\n",
    "# Выбираем случайных пользователей (оригинальные user_id)\n",
    "random_users = np.random.choice(ratings_df['user_id'].unique(), size=5)\n",
    "\n",
    "print(\"\\nПерсонализированные рекомендации (топ-5 аниме) для случайных пользователей:\")\n",
    "for user_id in random_users:\n",
    "    user_idx = user_id_map[user_id]\n",
    "    \n",
    "    # Предсказания для всех аниме для выбранного пользователя\n",
    "    user_tensor = torch.tensor([user_idx] * num_items, dtype=torch.long).to(device)\n",
    "    item_tensor = torch.tensor(range(num_items), dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_tensor, item_tensor).cpu().numpy()\n",
    "\n",
    "    # Выбираем топ-5 рекомендованных аниме (idx)\n",
    "    top_indices = predictions.argsort()[-5:][::-1]\n",
    "    top_anime_ids = [idx_to_anime[idx] for idx in top_indices]\n",
    "    \n",
    "    # Получаем названия\n",
    "    top_titles = anime_df[anime_df['anime_id'].isin(top_anime_ids)]['title'].tolist()\n",
    "\n",
    "    print(f\"Пользователь {user_id}: Рекомендуемые аниме: {top_titles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce667cd",
   "metadata": {},
   "source": [
    "Ключевые этапы:\n",
    "1. Подготовка датасета\n",
    "2. Подготовка и обучение модели\n",
    "3. Оценка модели на тестовом наборе\n",
    "4. Вычисление метрик\n",
    "\n",
    "Для улучшения метрик можно увеличить эмбеддинг\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba964f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.534317907275505, Train RMSE: 1.2387, Train MAE: 0.9377\n",
      "Epoch 2, Loss: 1.322184602504597, Train RMSE: 1.1499, Train MAE: 0.8671\n",
      "Epoch 3, Loss: 1.2624238546147988, Train RMSE: 1.1236, Train MAE: 0.8459\n",
      "Epoch 4, Loss: 1.2235452300890997, Train RMSE: 1.1061, Train MAE: 0.8320\n",
      "Epoch 5, Loss: 1.187540085458911, Train RMSE: 1.0897, Train MAE: 0.8189\n",
      "Epoch 6, Loss: 1.1504311103300022, Train RMSE: 1.0726, Train MAE: 0.8055\n",
      "Epoch 7, Loss: 1.1133915421292284, Train RMSE: 1.0552, Train MAE: 0.7917\n",
      "Epoch 8, Loss: 1.0796393847186074, Train RMSE: 1.0391, Train MAE: 0.7787\n",
      "Epoch 9, Loss: 1.0522195427534786, Train RMSE: 1.0258, Train MAE: 0.7688\n",
      "Epoch 10, Loss: 1.0256393670765422, Train RMSE: 1.0127, Train MAE: 0.7586\n",
      "\n",
      "Test RMSE: 1.1133, Test MAE: 0.8409\n",
      "\n",
      "Персонализированные рекомендации (топ-5 аниме) для случайных пользователей:\n",
      "Пользователь 18309: Рекомендуемые аниме: ['Clannad', 'Clannad: After Story', 'Suzumiya Haruhi no Shoushitsu', 'Steins;Gate', 'Gintama・ゑｽｰ']\n",
      "Пользователь 34459: Рекомендуемые аниме: ['Code Geass: Hangyaku no Lelouch R2', 'Angel Beats!', 'Gintama Movie 2: Kanketsu-hen - Yorozuya yo Eien Nare', 'No Game No Life', 'Dragon Ball Super Movie: Broly']\n",
      "Пользователь 91729: Рекомендуемые аниме: ['Steins;Gate', 'Koe no Katachi', 'Gintama・ゑｽｰ', 'Kimi no Na wa.', 'Dragon Ball Super Movie: Broly']\n",
      "Пользователь 23327: Рекомендуемые аниме: ['Mononoke', 'Ashita no Joe 2', 'Marco: Haha wo Tazunete Sanzenri', 'Hyouge Mono', 'Yuuki Yuuna wa Yuusha de Aru: Washio Sumi no Shou 3 - Yakusoku']\n",
      "Пользователь 20806: Рекомендуемые аниме: ['Ginga Eiyuu Densetsu', 'Major S6', 'Steins;Gate', 'Gintama Movie 2: Kanketsu-hen - Yorozuya yo Eien Nare', 'Gintama・ゑｽｰ']\n"
     ]
    }
   ],
   "source": [
    "# Определяем нейросетевую модель для коллаборативной фильтрации\n",
    "class RecommenderNN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        super(RecommenderNN, self).__init__()\n",
    "        # Эмбеддинги пользователей и аниме\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Полносвязные слои для предсказания рейтинга\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Получаем эмбеддинги пользователя и аниме\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "\n",
    "        # Объединяем эмбеддинги\n",
    "        x = torch.cat([user_emb, item_emb], dim=1)\n",
    "\n",
    "        # Пропускаем через полносвязные слои\n",
    "        return self.fc_layers(x).squeeze()\n",
    "    \n",
    "# Определяем количество пользователей и аниме\n",
    "num_users = len(user_id_map)\n",
    "num_items = len(anime_id_map)\n",
    "\n",
    "# Создаём датасеты и загрузчики данных\n",
    "dataset = RatingsDataset(ratings_df)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "\n",
    "# Инициализация модели\n",
    "model = RecommenderNN(num_users, num_items).to(device)\n",
    "\n",
    "# Определяем функцию потерь (MSE) и оптимизатор (Adam)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "# Обучение модели\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_ratings = []\n",
    "    for users, items, ratings in train_loader:\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().detach().numpy())\n",
    "        all_ratings.extend(ratings.cpu().detach().numpy())\n",
    "\n",
    "    # Средняя ошибка предсказания на тренировочной выборке\n",
    "    rmse = math.sqrt(mean_squared_error(all_ratings, all_predictions))\n",
    "    mae = mean_absolute_error(all_ratings, all_predictions)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}, Train RMSE: {rmse:.4f}, Train MAE: {mae:.4f}')\n",
    "\n",
    "    \n",
    "# Оценка модели на тестовом наборе\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_ratings = []\n",
    "with torch.no_grad():\n",
    "    for users, items, ratings in test_loader:\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        predictions = model(users, items)\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "        test_ratings.extend(ratings.cpu().numpy())\n",
    "\n",
    "# Средняя ошибка на тестовом наборе\n",
    "test_rmse = math.sqrt(mean_squared_error(test_ratings, test_predictions))\n",
    "test_mae = mean_absolute_error(test_ratings, test_predictions)\n",
    "\n",
    "print(f'\\nTest RMSE: {test_rmse:.4f}, Test MAE: {test_mae:.4f}')\n",
    "\n",
    "idx_to_anime = {v: k for k, v in anime_id_map.items()}\n",
    "\n",
    "# Выбираем случайных пользователей (оригинальные user_id)\n",
    "random_users = np.random.choice(ratings_df['user_id'].unique(), size=5)\n",
    "\n",
    "print(\"\\nПерсонализированные рекомендации (топ-5 аниме) для случайных пользователей:\")\n",
    "for user_id in random_users:\n",
    "    user_idx = user_id_map[user_id]\n",
    "    \n",
    "    # Предсказания для всех аниме для выбранного пользователя\n",
    "    user_tensor = torch.tensor([user_idx] * num_items, dtype=torch.long).to(device)\n",
    "    item_tensor = torch.tensor(range(num_items), dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_tensor, item_tensor).cpu().numpy()\n",
    "\n",
    "    # Выбираем топ-5 рекомендованных аниме (idx)\n",
    "    top_indices = predictions.argsort()[-5:][::-1]\n",
    "    top_anime_ids = [idx_to_anime[idx] for idx in top_indices]\n",
    "    \n",
    "    # Получаем названия\n",
    "    top_titles = anime_df[anime_df['anime_id'].isin(top_anime_ids)]['title'].tolist()\n",
    "\n",
    "    print(f\"Пользователь {user_id}: Рекомендуемые аниме: {top_titles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8ef72",
   "metadata": {},
   "source": [
    "Видим улучшение метрик как на эпохах так и на тестовой выборке. Увеличение количества эпох даст лишь переобучение"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
